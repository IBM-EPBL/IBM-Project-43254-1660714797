{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vR4Wx5slOpGm"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import Convolution2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jf6Cwpk9RLwk"
   },
   "outputs": [],
   "source": [
    "train_path = \"/content/Flowers-Dataset/flowers/Train\"\n",
    "test_path = \"/content/Flowers-Dataset/flowers/Test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0zFMzkbBD8WC"
   },
   "source": [
    "# Assignment 3\n",
    "# **1. Image Augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CFRDm1PhTNjV",
    "outputId": "d0c9089b-6f70-48c8-aa84-82dd16552ba0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/Flowers-Dataset/flowers/Train/daisy\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "sub_path = train_path + \"/daisy\"\n",
    "print(sub_path)\n",
    "for img in os.listdir(sub_path):\n",
    "  image_path = sub_path + \"/\" + img\n",
    "  img_arr = cv2.imread(image_path)\n",
    "  img = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "  img = cv2.resize(img,(224,224))\n",
    "  img = img.reshape(224,224,3)\n",
    "  x_train.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BwElT99CTY-N",
    "outputId": "a36b250b-d8d0-4f7f-8814-dc52e67bd42f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/Flowers-Dataset/flowers/Train/dandelion\n"
     ]
    }
   ],
   "source": [
    "sub_path = train_path + \"/dandelion\"\n",
    "print(sub_path)\n",
    "for img in os.listdir(sub_path):\n",
    "  image_path = sub_path + \"/\" + img\n",
    "  img_arr = cv2.imread(image_path)\n",
    "  img = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "  img = cv2.resize(img,(224,224))\n",
    "  img = img.reshape(224,224,3)\n",
    "  x_train.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fAqfYv0TTczV",
    "outputId": "94446e2a-78fd-47ba-b3bf-dcb72b1d2de7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/Flowers-Dataset/flowers/Train/rose\n"
     ]
    }
   ],
   "source": [
    "sub_path = train_path + \"/rose\"\n",
    "print(sub_path)\n",
    "for img in os.listdir(sub_path):\n",
    "  image_path = sub_path + \"/\" + img\n",
    "  img_arr = cv2.imread(image_path)\n",
    "  img = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "  img = cv2.resize(img,(224,224))\n",
    "  img = img.reshape(224,224,3)\n",
    "  x_train.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l-wpyMSSTeiV",
    "outputId": "6eebbdf3-16dd-44fc-9be3-f9bd38e61365"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/Flowers-Dataset/flowers/Train/sunflower\n"
     ]
    }
   ],
   "source": [
    "sub_path = train_path + \"/sunflower\"\n",
    "print(sub_path)\n",
    "for img in os.listdir(sub_path):\n",
    "  image_path = sub_path + \"/\" + img\n",
    "  img_arr = cv2.imread(image_path)\n",
    "  img = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "  img = cv2.resize(img,(224,224))\n",
    "  img = img.reshape(224,224,3)\n",
    "  x_train.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W4CufkYNTged",
    "outputId": "ddc4c99e-108e-404f-95f1-f9c498091e0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/Flowers-Dataset/flowers/Train/tulip\n"
     ]
    }
   ],
   "source": [
    "sub_path = train_path + \"/tulip\"\n",
    "print(sub_path)\n",
    "for img in os.listdir(sub_path):\n",
    "  image_path = sub_path + \"/\" + img\n",
    "  img_arr = cv2.imread(image_path)\n",
    "  img = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "  img = cv2.resize(img,(224,224))\n",
    "  img = img.reshape(224,224,3)\n",
    "  x_train.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "z80Ue8N8TmaN"
   },
   "outputs": [],
   "source": [
    "x_test = []\n",
    "sub_path=test_path+\"/daisy\"\n",
    "for img in os.listdir(sub_path):\n",
    "  image_path=sub_path+\"/\"+img\n",
    "  img_arr=cv2.imread(image_path)\n",
    "  img = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "  img = cv2.resize(img,(224,224))\n",
    "  img = img.reshape(224,224,3)\n",
    "  x_test.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xwPwa5_MTrXu"
   },
   "outputs": [],
   "source": [
    "sub_path=test_path+\"/dandelion\"\n",
    "for img in os.listdir(sub_path):\n",
    "  image_path=sub_path+\"/\"+img\n",
    "  img_arr=cv2.imread(image_path)\n",
    "  img = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "  img = cv2.resize(img,(224,224))\n",
    "  img = img.reshape(224,224,3)\n",
    "  x_test.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "EfAhi5yzTuiG"
   },
   "outputs": [],
   "source": [
    "sub_path=test_path+\"/rose\"\n",
    "for img in os.listdir(sub_path):\n",
    "  image_path=sub_path+\"/\"+img\n",
    "  img_arr=cv2.imread(image_path)\n",
    "  img = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "  img = cv2.resize(img,(224,224))\n",
    "  img = img.reshape(224,224,3)\n",
    "  x_test.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "522nOGoTTxcm"
   },
   "outputs": [],
   "source": [
    "sub_path=test_path+\"/sunflower\"\n",
    "for img in os.listdir(sub_path):\n",
    "  image_path=sub_path+\"/\"+img\n",
    "  img_arr=cv2.imread(image_path)\n",
    "  img = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "  img = cv2.resize(img,(224,224))\n",
    "  img = img.reshape(224,224,3)\n",
    "  x_test.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "wdTsBltmTy2t"
   },
   "outputs": [],
   "source": [
    "sub_path=test_path+\"/tulip\"\n",
    "for img in os.listdir(sub_path):\n",
    "  image_path=sub_path+\"/\"+img\n",
    "  img_arr=cv2.imread(image_path)\n",
    "  img = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "  img = cv2.resize(img,(224,224))\n",
    "  img = img.reshape(224,224,3)\n",
    "  x_test.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kPQkEh2gT0bF",
    "outputId": "690ed473-dbc7-4c41-d5a6-e2deaff9935d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3192, 224, 224, 3)\n",
      "(1125, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "train_x = np.array(x_train)\n",
    "test_x = np.array(x_test)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(test_x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "E5yqmwc_T2Ke"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1/255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GP9NS6UhT3UP",
    "outputId": "0a23d52f-3d81-4a6c-a15a-04ce1fbcdaa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3192 images belonging to 5 classes.\n",
      "Found 1125 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(train_path,\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(test_path,\n",
    "                                            target_size = (224, 224),\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "uIqXPHPfT5OV"
   },
   "outputs": [],
   "source": [
    "train_y = training_set.classes\n",
    "test_y = test_set.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kXuJzmoHUOJW",
    "outputId": "208f4601-9061-4e71-e838-c757d0c3f0b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflower': 3, 'tulip': 4}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "K-0XksS6UTk9"
   },
   "outputs": [],
   "source": [
    "classes = [\"daisy\",\"dandelion\",\"rose\",\"sunflower\",\"tulip\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "l4ZcJyCdUU6n"
   },
   "outputs": [],
   "source": [
    "train_x=train_x/255.0\n",
    "test_x=test_x/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-8AxyA5EJ3q"
   },
   "source": [
    "# **2. Create Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "c12530YpUXed"
   },
   "outputs": [],
   "source": [
    "#Building the CNN\n",
    "# Initializing the CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APlAxOZXEzwR"
   },
   "source": [
    "# **3. Add Layers (Convolution,MaxPooling,Flatten,Dense-(Hidden Layers),Output)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "3jh2y6fZE6bi"
   },
   "outputs": [],
   "source": [
    "# First convolution layer and pooling\n",
    "classifier.add(Convolution2D(32, (3, 3), input_shape=(224, 224, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Second convolution layer and pooling\n",
    "classifier.add(Convolution2D(32, (3, 3), activation='relu'))\n",
    "# input_shape is going to be the pooled feature maps from the previous convolution layer\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening the layers\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Adding a fully connected layer\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "classifier.add(Dropout(0.40))\n",
    "classifier.add(Dense(units=96, activation='relu'))\n",
    "classifier.add(Dropout(0.40))\n",
    "classifier.add(Dense(units=64, activation='relu'))\n",
    "classifier.add(Dense(units=5, activation='softmax')) # softmax for more than 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gSm3WfjRE5sq"
   },
   "source": [
    "\n",
    "\n",
    "# **4. Compile The Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "SGjnWEmIFBL6"
   },
   "outputs": [],
   "source": [
    "# Compiling the CNN\n",
    "classifier.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6kFlKoitUoNt",
    "outputId": "33f93983-003c-4274-df2e-cebf5a29f483"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 93312)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               11944064  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 96)                12384     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                6208      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,973,125\n",
      "Trainable params: 11,973,125\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgYO4gJnFEE6"
   },
   "source": [
    "# **5. Fit The Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NrVjBwwMUq21",
    "outputId": "48a7911b-8ad1-42e6-8fab-317f3d4ae50c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 172s 2s/step - loss: 1.4816 - accuracy: 0.3506 - val_loss: 1.4133 - val_accuracy: 0.3422\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 177s 2s/step - loss: 1.2649 - accuracy: 0.4574 - val_loss: 1.1625 - val_accuracy: 0.4791\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 173s 2s/step - loss: 1.1021 - accuracy: 0.5467 - val_loss: 1.1519 - val_accuracy: 0.5538\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 176s 2s/step - loss: 0.8770 - accuracy: 0.6454 - val_loss: 1.1342 - val_accuracy: 0.5733\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 173s 2s/step - loss: 0.6691 - accuracy: 0.7378 - val_loss: 1.1589 - val_accuracy: 0.6142\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 173s 2s/step - loss: 0.4551 - accuracy: 0.8349 - val_loss: 1.5508 - val_accuracy: 0.6027\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 174s 2s/step - loss: 0.3381 - accuracy: 0.8819 - val_loss: 1.7510 - val_accuracy: 0.5867\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 175s 2s/step - loss: 0.2338 - accuracy: 0.9173 - val_loss: 1.7031 - val_accuracy: 0.6151\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 174s 2s/step - loss: 0.1846 - accuracy: 0.9455 - val_loss: 1.9242 - val_accuracy: 0.5858\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 173s 2s/step - loss: 0.1756 - accuracy: 0.9561 - val_loss: 1.7766 - val_accuracy: 0.5929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f216b117f50>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(train_x, train_y, epochs=10, validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzeiUgo3FJdK"
   },
   "source": [
    "# **6. Save The Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "1b14gGv3ri28"
   },
   "outputs": [],
   "source": [
    "classifier.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "la8wkW7Tu0ps",
    "outputId": "9de2b9af-3e07-43b6-dbad-66f2b9b3f982"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 15s 405ms/step - loss: 1.7766 - accuracy: 0.5929\n"
     ]
    }
   ],
   "source": [
    "loss, acc = classifier.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7TOGWuXCJKz"
   },
   "source": [
    "# **7. SUCCESSFULLY PREDICTED DAISY IMAGE FROM TEST IMAGES (Test The Model)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SRqMYVarB1qC",
    "outputId": "851096a6-331a-41b3-c18b-5e251e770f7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daisy\n"
     ]
    }
   ],
   "source": [
    "img = \"/content/Flowers-Dataset/flowers/Test/daisy/1150395827_6f94a5c6e4_n.jpg\"\n",
    "\n",
    "test = []\n",
    "img_arr = cv2.imread(img)\n",
    "\n",
    "img1 = cv2.resize(img_arr,(224,224))\n",
    "img1 = img1.reshape(224,224,3)\n",
    "\n",
    "test.append(img1)\n",
    "test_img = np.array(test)\n",
    "test_img = test_img/255\n",
    "\n",
    "pred = classifier.predict(test_img)\n",
    "print(classes[np.argmax(pred)])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
